{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries  \n",
    "import os  \n",
    "import json  \n",
    "import openai  \n",
    "from dotenv import load_dotenv  \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import Vector  \n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from IPython.display import display, HTML, JSON, Markdown\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\") \n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\") \n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\") \n",
    " \n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") \n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = \"gpt-35-turbo-0613\"\n",
    "OPENAI_MODEL_NAME = \"gpt-35-turbo-0613\"\n",
    "OPENAI_DEPLOYMENT_VERSION = \"2023-07-01-preview\"\n",
    "\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_MODEL_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_MODEL_NAME\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OPENAI_DEPLOYMENT_VERSION\n",
    "openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "#---\n",
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "COGNITIVE_SEARCH_INDEX_NAME = \"cognitive-search-vectordb-index_v2\"\n",
    "search_client = SearchClient(service_endpoint, index_name=COGNITIVE_SEARCH_INDEX_NAME, credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(page):\n",
    "    response = openai.Embedding.create(\n",
    "        input=page, engine=\"text-embedding-ada-002\")\n",
    "   \n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions (for calling); search in azure cognitive search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(topic, query, topic_filter):\n",
    "    \n",
    "    print (\"In function: get_info...\\n\")\n",
    "    print (f\"topic: {topic}\\n\")\n",
    "    print (f\"query: {query}\\n\")\n",
    "    print (f\"topic_filter: {topic_filter}\\n\")\n",
    "    \n",
    "    results = search_client.search(\n",
    "    search_text=query,\n",
    "    filter=topic_filter,\n",
    "    vector=generate_embeddings(query), top_k=3,  \n",
    "    vector_fields=\"textVector\",\n",
    "    query_type=\"semantic\",\n",
    "    query_language=\"en-us\",\n",
    "    semantic_configuration_name='vectordb-semantic-config',\n",
    "    query_caption=\"extractive\",\n",
    "    query_answer=\"extractive\",\n",
    "    select=[\"source\", \"text\"],\n",
    "    top=3)\n",
    "    \n",
    "\n",
    "    semantic_answers = results.get_answers()\n",
    "    semantic_prompt = \"\"\n",
    "    \n",
    "    for answer in semantic_answers:\n",
    "        if answer.highlights:\n",
    "            semantic_prompt += f\"topic: {topic}; topic_text: {answer.highlights}\\n\"\n",
    "        else:\n",
    "            semantic_prompt += f\"topic: {topic }; topic_text: {answer.text}\\n\"\n",
    "            \n",
    "    print (f\"final semantic prompt: {semantic_prompt}\")\n",
    "    \n",
    "    query_prompt = \"\"\n",
    "    \n",
    "    for result in results:\n",
    "        query_prompt += f\"Text: {result['text']}\\n\"\n",
    "        \n",
    "    print (f\"final query prompt: {query_prompt}\")\n",
    "    \n",
    "    if semantic_prompt:\n",
    "        return semantic_prompt\n",
    "    return query_prompt  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\" Assistant is a large language model designed to help employees of a company to find answers to their questions for various \n",
    "technical topics.\n",
    "You have access to an Azure Cognitive Search index that contains a large amount of technical documentation on different topics.\n",
    "You can search for the asked information in the index and return the most relevant results to the user. \n",
    "The index contains information about the following topics: Semantic Kernel, Langchain, and others.\n",
    "You are designed to be an interactive assistant, so you can ask the user for more information if needed to find the most relevant answer.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"Which programing languages are supported by semantic kernel?\"}]\n",
    "    \n",
    "functions = [\n",
    "        {\n",
    "            \"name\": \"get_info\",\n",
    "            \"description\": \"get detailed information about asked topic from Azure Cognitive Search\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"the domain of the question being asked, such as the semantic kernel, langchain, etc.\",\n",
    "                    },\n",
    "                    \"query\": {\n",
    "                        \"type\" : \"string\",\n",
    "                        \"description\": \"the question that was asked\",\n",
    "                        \n",
    "                    },\n",
    "                    \"topic_filter\": {\n",
    "                        \"type\" : \"string\",\n",
    "                        \"description\": \"\"\"The filter to apply for the topic. Generate the filter using the following format: topic eq 'Semantic Kernel')\n",
    "                        If you are not sure about the topic, generate empty filter: topic/any(i: i eq '')\"\"\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"topic\",\"query\",\"topic_filter\"],\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "available_functions = {\n",
    "            \"get_info\": get_info,\n",
    "        } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "        deployment_id = \"gpt-35-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        temperature=0.2,\n",
    "        function_call=\"auto\", \n",
    "    )\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting all parts togther\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qna(messages, functions, available_functions):\n",
    "    \n",
    "    #1. Ask GPT to find matching function\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id = \"gpt-35-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        temperature=0.2,\n",
    "        function_call=\"auto\", \n",
    "    )\n",
    "    \n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "    \n",
    "    #2 check if the model found a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        print(\"Recommended function:\")\n",
    "        print(response_message.get(\"function_call\"))\n",
    "        \n",
    "        #3. Run the function\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        if function_name not in available_functions:\n",
    "            return \"Function \" + function_name + \" does not exist\"\n",
    "        function_to_call = available_functions[function_name] \n",
    "        \n",
    "        # verify function has correct number of arguments\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        print (f\"Function arguments:{function_args}\")\n",
    "        function_response = function_to_call(**function_args) \n",
    "        \n",
    "        print(\"Output of function call:\")\n",
    "        print(function_response)\n",
    "        print()\n",
    "        #4. Ask GPT to find matching function\n",
    "        \n",
    "        # adding assistant response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": response_message[\"role\"],\n",
    "                \"name\": response_message[\"function_call\"][\"name\"],\n",
    "                \"content\": response_message[\"function_call\"][\"arguments\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # adding function response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "        \n",
    "        print(\"Messages in second request:\")\n",
    "        for message in messages:\n",
    "            print(message)\n",
    "        print()\n",
    "        \n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            messages=messages,\n",
    "            deployment_id= \"gpt-35-turbo-0613\"\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "        return second_response\n",
    "    else:\n",
    "        print(\"No function call found\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended function:\n",
      "{\n",
      "  \"name\": \"get_info\",\n",
      "  \"arguments\": \"{\\n  \\\"topic\\\": \\\"Semantic Kernel\\\",\\n  \\\"query\\\": \\\"supported programming languages\\\",\\n  \\\"topic_filter\\\": \\\"topic eq 'Semantic Kernel'\\\"\\n}\"\n",
      "}\n",
      "Function arguments:{'topic': 'Semantic Kernel', 'query': 'supported programming languages', 'topic_filter': \"topic eq 'Semantic Kernel'\"}\n",
      "In function: get_info...\n",
      "\n",
      "topic: Semantic Kernel\n",
      "\n",
      "query: supported programming languages\n",
      "\n",
      "topic_filter: topic eq 'Semantic Kernel'\n",
      "\n",
      "final semantic prompt: \n",
      "final query prompt: Text: Step Component Descr iption\n",
      "that have already been loaded into the kernel to create additional steps.\n",
      "This is similar to how ChatGPT, Bing, and Microsoft 365 Copilot combines\n",
      "plugins together in their experiences.\n",
      "2.3 Connectors To get additional data or to perform autonomous actions, you can use out-\n",
      "of-the-box plugins like the Microsoft Graph Connector kit or create a\n",
      "custom connector to provide data to your own services.\n",
      "2.4 Custom\n",
      "pluginsAs a developer, you can create custom plugins that run inside of Semantic\n",
      "Kernel. These plugins can consist of either LLM prompts (semantic\n",
      "functions) or native C# or Python code (native function). This allows you to\n",
      "add new AI capabilities and integrate your existing apps and services into\n",
      "Semantic K ernel.\n",
      "3 Response Once the kernel is done, you can send the response back to the user to let\n",
      "them know the process is complete.\n",
      "To make sure all developers can take advantage of our learnings building Copilots, we\n",
      "have released Semantic K ernel as an open-source project  on GitHub. T oday, we\n",
      "provide the SDK in .NET and Python flavors (T ypescript and Java are coming soon). For a\n",
      "full list of what is supported in each language, see supported languages .\n",
      "Semantic Kernel is open-source\n",
      "Text: Supported Semantic Kernel languages\n",
      "Article ‚Ä¢07/18/2023\n",
      "Semantic K ernel plans on providing support to the following languages:\n",
      "While the overall architecture of the kernel is consistent across all languages, we made\n",
      "sure the SDK for each language follows common paradigms and styles in each language\n",
      "to make it feel native and easy to use.\n",
      "Today, not all features are available in all languages. The following tables show which\n",
      "features are available in each language. The üîÑ  symbol indicates that the feature is\n",
      "partially implemented, please see the associated note column for more details. The ‚ùå\n",
      "symbol indicates that the feature is not yet available in that language; if you would like\n",
      "to see a feature implemented in a language, please consider contributing to the project\n",
      "or opening an issue .\n",
      "Services C# Python JavaNotes\n",
      "TextGeneration ‚úÖ‚úÖ‚úÖ Example: T ext-Davinci-003\n",
      "TextEmbeddings ‚úÖ‚úÖ‚úÖ Example: T ext-Embeddings-Ada-002\n",
      "ChatCompletion ‚úÖ‚úÖ‚úÖ Example: GPT4, Chat-GPTÔºó Note\n",
      "Skills are currently being renamed to plugins. This article has been updated to\n",
      "reflect the latest terminology, but some images and code samples may still refer to\n",
      "skills.\n",
      "C#ÔºÇ\n",
      "PythonÔºÇ\n",
      "Java ( available here ) ÔºÇ\n",
      "Available features\n",
      "AI Services\n",
      "Text: Responsible AI and Semantic Kernel\n",
      "Article ‚Ä¢05/23/2023\n",
      "An AI system includes not only the technology, but also the people who will use it, the\n",
      "people who will be affected by it, and the environment in which it is deployed. Creating\n",
      "a system that is fit for its intended purpose requires an understanding of how the\n",
      "technology works, what its capabilities and limitations are, and how to achieve the best\n",
      "performance. Microsoft‚Äôs T ransparency Notes are intended to help you understand how\n",
      "our AI technology works, the choices system owners can make that influence system\n",
      "performance and behavior, and the importance of thinking about the whole system,\n",
      "including the technology, the people, and the environment. Y ou can use T ransparency\n",
      "Notes when developing or deploying your own system, or share them with the people\n",
      "who will use or be affected by your system.\n",
      "Microsoft‚Äôs T ransparency Notes are part of a broader effort at Microsoft to put our AI\n",
      "Principles into practice. T o find out more, see the Microsoft AI principles .\n",
      "Semantic K ernel (SK) is a lightweight SDK that lets you easily mix conventional\n",
      "programming languages with the latest in Large Language Model (LLM) AI \"prompts\"\n",
      "with templating, chaining, and planning capabilities out-of-the-box.\n",
      "Semantic K ernel (SK) builds upon the following five concepts:\n",
      "Concept Shor t Descr iption\n",
      "Kernel The kernel orchestrates a user's ASK expressed as a goal\n",
      "Planner Planner breaks it down into steps based upon resources that are available\n",
      "Plugins Plugins are customizable resources built from LLM AI prompts and native codeWhat is a Transparency Note?\n",
      "Introduction to Semantic Kernel\n",
      "The basics of Semantic Kernel\n",
      "\n",
      "Output of function call:\n",
      "Text: Step Component Descr iption\n",
      "that have already been loaded into the kernel to create additional steps.\n",
      "This is similar to how ChatGPT, Bing, and Microsoft 365 Copilot combines\n",
      "plugins together in their experiences.\n",
      "2.3 Connectors To get additional data or to perform autonomous actions, you can use out-\n",
      "of-the-box plugins like the Microsoft Graph Connector kit or create a\n",
      "custom connector to provide data to your own services.\n",
      "2.4 Custom\n",
      "pluginsAs a developer, you can create custom plugins that run inside of Semantic\n",
      "Kernel. These plugins can consist of either LLM prompts (semantic\n",
      "functions) or native C# or Python code (native function). This allows you to\n",
      "add new AI capabilities and integrate your existing apps and services into\n",
      "Semantic K ernel.\n",
      "3 Response Once the kernel is done, you can send the response back to the user to let\n",
      "them know the process is complete.\n",
      "To make sure all developers can take advantage of our learnings building Copilots, we\n",
      "have released Semantic K ernel as an open-source project  on GitHub. T oday, we\n",
      "provide the SDK in .NET and Python flavors (T ypescript and Java are coming soon). For a\n",
      "full list of what is supported in each language, see supported languages .\n",
      "Semantic Kernel is open-source\n",
      "Text: Supported Semantic Kernel languages\n",
      "Article ‚Ä¢07/18/2023\n",
      "Semantic K ernel plans on providing support to the following languages:\n",
      "While the overall architecture of the kernel is consistent across all languages, we made\n",
      "sure the SDK for each language follows common paradigms and styles in each language\n",
      "to make it feel native and easy to use.\n",
      "Today, not all features are available in all languages. The following tables show which\n",
      "features are available in each language. The üîÑ  symbol indicates that the feature is\n",
      "partially implemented, please see the associated note column for more details. The ‚ùå\n",
      "symbol indicates that the feature is not yet available in that language; if you would like\n",
      "to see a feature implemented in a language, please consider contributing to the project\n",
      "or opening an issue .\n",
      "Services C# Python JavaNotes\n",
      "TextGeneration ‚úÖ‚úÖ‚úÖ Example: T ext-Davinci-003\n",
      "TextEmbeddings ‚úÖ‚úÖ‚úÖ Example: T ext-Embeddings-Ada-002\n",
      "ChatCompletion ‚úÖ‚úÖ‚úÖ Example: GPT4, Chat-GPTÔºó Note\n",
      "Skills are currently being renamed to plugins. This article has been updated to\n",
      "reflect the latest terminology, but some images and code samples may still refer to\n",
      "skills.\n",
      "C#ÔºÇ\n",
      "PythonÔºÇ\n",
      "Java ( available here ) ÔºÇ\n",
      "Available features\n",
      "AI Services\n",
      "Text: Responsible AI and Semantic Kernel\n",
      "Article ‚Ä¢05/23/2023\n",
      "An AI system includes not only the technology, but also the people who will use it, the\n",
      "people who will be affected by it, and the environment in which it is deployed. Creating\n",
      "a system that is fit for its intended purpose requires an understanding of how the\n",
      "technology works, what its capabilities and limitations are, and how to achieve the best\n",
      "performance. Microsoft‚Äôs T ransparency Notes are intended to help you understand how\n",
      "our AI technology works, the choices system owners can make that influence system\n",
      "performance and behavior, and the importance of thinking about the whole system,\n",
      "including the technology, the people, and the environment. Y ou can use T ransparency\n",
      "Notes when developing or deploying your own system, or share them with the people\n",
      "who will use or be affected by your system.\n",
      "Microsoft‚Äôs T ransparency Notes are part of a broader effort at Microsoft to put our AI\n",
      "Principles into practice. T o find out more, see the Microsoft AI principles .\n",
      "Semantic K ernel (SK) is a lightweight SDK that lets you easily mix conventional\n",
      "programming languages with the latest in Large Language Model (LLM) AI \"prompts\"\n",
      "with templating, chaining, and planning capabilities out-of-the-box.\n",
      "Semantic K ernel (SK) builds upon the following five concepts:\n",
      "Concept Shor t Descr iption\n",
      "Kernel The kernel orchestrates a user's ASK expressed as a goal\n",
      "Planner Planner breaks it down into steps based upon resources that are available\n",
      "Plugins Plugins are customizable resources built from LLM AI prompts and native codeWhat is a Transparency Note?\n",
      "Introduction to Semantic Kernel\n",
      "The basics of Semantic Kernel\n",
      "\n",
      "\n",
      "Messages in second request:\n",
      "{'role': 'system', 'content': ' Assistant is a large language model designed to help employees of a company to find answers to their questions for various \\ntechnical topics.\\nYou have access to an Azure Cognitive Search index that contains a large amount of technical documentation on different topics.\\nYou can search for the asked information in the index and return the most relevant results to the user. \\nThe index contains information about the following topics: Semantic Kernel, Langchain, and others.\\nYou are designed to be an interactive assistant, so you can ask the user for more information if needed to find the most relevant answer.\\n'}\n",
      "{'role': 'user', 'content': 'Which programing languages are supported by semantic kernel?'}\n",
      "{'role': 'assistant', 'name': 'get_info', 'content': '{\\n  \"topic\": \"Semantic Kernel\",\\n  \"query\": \"supported programming languages\",\\n  \"topic_filter\": \"topic eq \\'Semantic Kernel\\'\"\\n}'}\n",
      "{'role': 'function', 'name': 'get_info', 'content': 'Text: Step Component Descr iption\\nthat have already been loaded into the kernel to create additional steps.\\nThis is similar to how ChatGPT, Bing, and Microsoft 365 Copilot combines\\nplugins together in their experiences.\\n2.3 Connectors To get additional data or to perform autonomous actions, you can use out-\\nof-the-box plugins like the Microsoft Graph Connector kit or create a\\ncustom connector to provide data to your own services.\\n2.4 Custom\\npluginsAs a developer, you can create custom plugins that run inside of Semantic\\nKernel. These plugins can consist of either LLM prompts (semantic\\nfunctions) or native C# or Python code (native function). This allows you to\\nadd new AI capabilities and integrate your existing apps and services into\\nSemantic K ernel.\\n3 Response Once the kernel is done, you can send the response back to the user to let\\nthem know the process is complete.\\nTo make sure all developers can take advantage of our learnings building Copilots, we\\nhave released Semantic K ernel as an open-source project  on GitHub. T oday, we\\nprovide the SDK in .NET and Python flavors (T ypescript and Java are coming soon). For a\\nfull list of what is supported in each language, see supported languages .\\nSemantic Kernel is open-source\\nText: Supported Semantic Kernel languages\\nArticle ‚Ä¢07/18/2023\\nSemantic K ernel plans on providing support to the following languages:\\nWhile the overall architecture of the kernel is consistent across all languages, we made\\nsure the SDK for each language follows common paradigms and styles in each language\\nto make it feel native and easy to use.\\nToday, not all features are available in all languages. The following tables show which\\nfeatures are available in each language. The üîÑ  symbol indicates that the feature is\\npartially implemented, please see the associated note column for more details. The ‚ùå\\nsymbol indicates that the feature is not yet available in that language; if you would like\\nto see a feature implemented in a language, please consider contributing to the project\\nor opening an issue .\\nServices C# Python JavaNotes\\nTextGeneration ‚úÖ‚úÖ‚úÖ Example: T ext-Davinci-003\\nTextEmbeddings ‚úÖ‚úÖ‚úÖ Example: T ext-Embeddings-Ada-002\\nChatCompletion ‚úÖ‚úÖ‚úÖ Example: GPT4, Chat-GPTÔºó Note\\nSkills are currently being renamed to plugins. This article has been updated to\\nreflect the latest terminology, but some images and code samples may still refer to\\nskills.\\nC#ÔºÇ\\nPythonÔºÇ\\nJava ( available here ) ÔºÇ\\nAvailable features\\nAI Services\\nText: Responsible AI and Semantic Kernel\\nArticle ‚Ä¢05/23/2023\\nAn AI system includes not only the technology, but also the people who will use it, the\\npeople who will be affected by it, and the environment in which it is deployed. Creating\\na system that is fit for its intended purpose requires an understanding of how the\\ntechnology works, what its capabilities and limitations are, and how to achieve the best\\nperformance. Microsoft‚Äôs T ransparency Notes are intended to help you understand how\\nour AI technology works, the choices system owners can make that influence system\\nperformance and behavior, and the importance of thinking about the whole system,\\nincluding the technology, the people, and the environment. Y ou can use T ransparency\\nNotes when developing or deploying your own system, or share them with the people\\nwho will use or be affected by your system.\\nMicrosoft‚Äôs T ransparency Notes are part of a broader effort at Microsoft to put our AI\\nPrinciples into practice. T o find out more, see the Microsoft AI principles .\\nSemantic K ernel (SK) is a lightweight SDK that lets you easily mix conventional\\nprogramming languages with the latest in Large Language Model (LLM) AI \"prompts\"\\nwith templating, chaining, and planning capabilities out-of-the-box.\\nSemantic K ernel (SK) builds upon the following five concepts:\\nConcept Shor t Descr iption\\nKernel The kernel orchestrates a user\\'s ASK expressed as a goal\\nPlanner Planner breaks it down into steps based upon resources that are available\\nPlugins Plugins are customizable resources built from LLM AI prompts and native codeWhat is a Transparency Note?\\nIntroduction to Semantic Kernel\\nThe basics of Semantic Kernel\\n'}\n",
      "\n",
      "Answer: The Semantic Kernel supports programming languages such as C#, Python, and Java. However, not all features are available in all languages. For a full list of supported features in each language, please refer to the documentation.\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\" Assistant is a large language model designed to help employees of a company to find answers to their questions for various \n",
    "technical topics.\n",
    "You have access to an Azure Cognitive Search index that contains a large amount of technical documentation on different topics.\n",
    "You can search for the asked information in the index and return the most relevant results to the user. \n",
    "The index contains information about the following topics: Semantic Kernel, Langchain, and others.\n",
    "You are designed to be an interactive assistant, so you can ask the user for more information if needed to find the most relevant answer.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"Which programing languages are supported by semantic kernel?\"}]\n",
    "    \n",
    "functions = [\n",
    "        {\n",
    "            \"name\": \"get_info\",\n",
    "            \"description\": \"get detailed information about asked topic from Azure Cognitive Search\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"the domain of the question being asked, such as the semantic kernel, langchain, etc.\",\n",
    "                    },\n",
    "                    \"query\": {\n",
    "                        \"type\" : \"string\",\n",
    "                        \"description\": \"the question that was asked\",\n",
    "                        \n",
    "                    },\n",
    "                    \"topic_filter\": {\n",
    "                        \"type\" : \"string\",\n",
    "                        \"description\": \"\"\"The filter to apply for the topic. Generate the filter using the following format: topic eq 'Semantic Kernel')\n",
    "                        If you are not sure about the topic, generate empty filter: topic/any(i: i eq '')\"\"\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"topic\",\"query\",\"topic_filter\"],\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "available_functions = {\n",
    "            \"get_info\": get_info,\n",
    "        } \n",
    "\n",
    "\n",
    "result = run_qna(messages, functions, available_functions)\n",
    "print(f\"Answer: {result['choices'][0]['message']['content']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
